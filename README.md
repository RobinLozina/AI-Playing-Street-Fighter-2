# Street Fighter II AI: Reinforcement Learning Project

This project demonstrates the implementation of a reinforcement learning (RL) agent trained to play Street Fighter II using Gym Retro, OpenAI's Gym toolkit, and custom ROM integration. The code and approach are inspired by NickNochnack's StreetFighterRL repository, adapted here to study the impact of parameter variations on model performance and gain practical insights into reinforcement learning concepts.

## Project Overview

The goal of this project is to train an RL model capable of playing Street Fighter II and investigate how modifying hyperparameters affects the model's success. The project serves as both a technical exploration of reinforcement learning and a case study in tuning parameters for optimal model performance. This notebook setup provides a foundation to understand key RL principles, such as state-action-reward mechanisms, environment interaction, and policy optimization.

## Motivation and Objectives

This project was developed to:

1. **Explore Reinforcement Learning**: Implementing an RL model within a game environment provides a hands-on way to learn how agents make decisions and optimize strategies through trial and error.

2. **Parameter Variation Study**: By altering various parameters (e.g., learning rate, gamma, and exploration rates), we can observe their effects on model performance, offering insights into hyperparameter tuning.

3. **Experimentation with Gym Retro**: Using Gym Retro allows for engaging with classic games while testing the RL algorithms in dynamic, visually complex environments.

## Project Structure

The project notebook provides a sequential flow from setting up dependencies, importing the ROM, and defining the reinforcement learning model, to tuning and training the agent.

## Credits

The code and approach are inspired by [NickNochnack's StreetFighterRL repository](https://github.com/nicknochnack/StreetFighterRL).
